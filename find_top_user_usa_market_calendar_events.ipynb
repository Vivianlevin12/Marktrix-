{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#before runing the code pip install the following: \n",
    "#pip install tensorflow\n",
    "#pip install tensorflow_text\n",
    "#pip install tensorflow_hub\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import tensorflow_hub as hub\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from marktrix.helpers import Helper\n",
    "from marktrix.calendar import Calendar, global_calendar\n",
    "from marktrix.user_data import UserData\n",
    "from marktrix.website_info import WebsiteInfo\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Load your API key from an environment variable or secret management service\n",
    "openai.api_key = \"sk-9GD2atPAt9M1Od4YaPWIew7J3BNSlWKiO1d0Z7z3\"\n",
    "\n",
    "#load universal sentence encoder\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "\n",
    "embed = hub.load(module_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_url = os.environ.get(\"MARKTRIX_MONGO\")\n",
    "client = MongoClient(mongo_url)\n",
    "db = client['marktrix-production']\n",
    "# db = client['marktrix-staging']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict best calendar events from USA market Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function that return max events embed similarity to user and target audience \n",
    "def predict_best_calendar_events(user_info, keyword, start_date, n_best):\n",
    "    #calculate events dates\n",
    "    events_start_date = start_date + timedelta(days = 7)\n",
    "    events_end_date = start_date + timedelta(days = 21)\n",
    "    keyword = str(keyword)\n",
    "    n_best = int(n_best)\n",
    "    \n",
    "    #user and website info\n",
    "    company_name = Helper.get_object_field(user_info, 'CompanyName')\n",
    "    company_industry = Helper.get_object_field(user_info, 'OwnIndustry')\n",
    "    site_desc = Helper.get_object_field(user_info, 'SiteDescription')\n",
    "    sol_desc = Helper.get_object_field(user_info, 'SolutionDescription')\n",
    "    num_one_benefit = Helper.get_object_field(user_info, 'NumberOneBenefit')\n",
    "    company_size = Helper.get_object_field(user_info, 'OwnCompanySize') \n",
    "    main_product_categories = str(Helper.get_object_field(user_info, 'MainProductCategories'))\n",
    "    #business_model = Helper.get_object_field(user_info, 'BusinessModel')  # for Tone\n",
    "    #business_model = Helper.business_model_desc(business_model)\n",
    "    #how_customer_deal_with_needs = Helper.get_object_field(user_info, 'HowCustomerDealWithNeeds')\n",
    "    #sol_change = Helper.get_object_field(user_info, 'WhatYourSolutionChange')\n",
    "    #why_sol_important = Helper.get_object_field(user_info, 'WhySolutionImportant')\n",
    "    company_text = keyword +' '+ company_name + ' ' + company_industry + ' ' + site_desc + ' ' + sol_desc + \\\n",
    "                    ' ' + num_one_benefit +  ' ' + company_size  + ' ' + main_product_categories\n",
    "       \n",
    "    \n",
    "    #create embeddings from company's text and target customers\n",
    "    company_text = tf.convert_to_tensor(company_text.astype(str), dtype=tf.string)\n",
    "    company_embed = embed(company_text)\n",
    "    \n",
    "    # target customer info\n",
    "    target_customer_description = Helper.get_object_field(user_info, 'TargetCustomerDescription')\n",
    "    positive_trends = Helper.get_object_field(user_info, 'PositiveTrends')\n",
    "    \n",
    "    target_customer_ages = Helper.get_object_field(user_info, 'TargetCustomerAges')\n",
    "    if target_customer_ages.iloc[0] != '' and type(target_customer_ages.iloc[0]) == list:\n",
    "        target_customer_ages = [Helper.customer_age_to_text(age) for age in target_customer_ages]\n",
    "        target_customer_ages = Helper.list_to_text(target_customer_ages)\n",
    "\n",
    "    target_customer_gender = Helper.get_object_field(user_info, 'TargetCustomerGender')\n",
    "    if target_customer_gender.iloc[0] != '' and type(target_customer_gender.iloc[0]) == list:\n",
    "        target_customer_gender = Helper.list_to_text(target_customer_gender)\n",
    "\n",
    "    target_customer_geo = Helper.get_object_field(user_info, 'TargetCustomerGeography')\n",
    "    if target_customer_geo.iloc[0] != '' and type(target_customer_geo.iloc[0]) == list:\n",
    "        target_customer_geo = Helper.list_to_text(target_customer_geo)\n",
    "\n",
    "     # decide if to use old or new\n",
    "    if target_customer_ages.iloc[0] or target_customer_gender.iloc[0] or target_customer_geo.iloc[0]:\n",
    "         target_customer_description = target_customer_ages + ' '  + target_customer_gender+ ' ' + target_customer_geo\n",
    "    \n",
    "    \n",
    "    target_customer_and_trends_text = target_customer_description + ' ' + positive_trends \n",
    "\n",
    "    \n",
    "    #If target customer text and trends is empty use Company_text\n",
    "    if  target_customer_and_trends_text is not '':\n",
    "        target_customer_and_trends_text= tf.convert_to_tensor(target_customer_and_trends_text.astype(str), dtype=tf.string)\n",
    "        target_customers_embed = embed(target_customer_and_trends_text)\n",
    "       \n",
    "    else:\n",
    "        target_customers_embed = embed(company_text)\n",
    "\n",
    "    \n",
    "    #get usa_market_calendar\n",
    "    usa_market_calendar = list(db.usa_market_calendar.find())\n",
    "    usa_market_calendar = pd.DataFrame(usa_market_calendar)\n",
    "    usa_market_calendar ['date'] = usa_market_calendar['date'].dt.date\n",
    "    mask = (usa_market_calendar['date'] > events_start_date) & (usa_market_calendar['date'] <= events_end_date)\n",
    "    conc_usa_market_events = usa_market_calendar.loc[mask]\n",
    "    conc_usa_market_events = conc_usa_market_events[['name','desc', 'date']] \n",
    "    conc_usa_market_events_name = conc_usa_market_events['name'] \n",
    "    conc_usa_market_events_desc = conc_usa_market_events['desc'] \n",
    "    conc_usa_market_events['text'] = conc_usa_market_events_name + ' ' + conc_usa_market_events_desc\n",
    "\n",
    "    #create embeddings from concurrent events texts\n",
    "    conc_usa_market_events['text'] = tf.convert_to_tensor(conc_usa_market_events['text'].astype(str), dtype=tf.string)\n",
    "    conc_usa_market_events_embed = embed(conc_usa_market_events['text'])\n",
    "        \n",
    "    #calculate target customer embed correlation with concurrent_events_embed \n",
    "    target_event_cos_sim = tf.keras.losses.cosine_similarity(conc_usa_market_events_embed, target_customers_embed)\n",
    "\n",
    "    #calculate company embed correlation with concurrent_events_embed\n",
    "    company_event_cos_sim = tf.keras.losses.cosine_similarity(conc_usa_market_events_embed, company_embed)\n",
    "\n",
    "\n",
    "    #calculates a similarity score based on combination of company and target customers similarity scores and contact with the best usa market events\n",
    "    similarity_score = target_event_cos_sim*0.5 + company_event_cos_sim*0.5\n",
    "    conc_usa_market_events['similarity_score'] =  similarity_score\n",
    "    conc_usa_market_events['similarity_score'] = conc_usa_market_events['similarity_score'].astype(float)\n",
    "    best = max(n_best,len(conc_usa_market_events['similarity_score']))\n",
    "    best = int(best)\n",
    "    df = conc_usa_market_events.nlargest(best, 'similarity_score')\n",
    "    df = df.sort_values(by = ['similarity_score'], ascending=False)\n",
    "    df = df[['name','desc', 'date','similarity_score']]            \n",
    "\n",
    "        \n",
    "    return df \n",
    "    #with dates (can be index), pred, event. - sorted top pred first, event is event object as in calendar (day or month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = UserData()\n",
    "website_info = WebsiteInfo()\n",
    "users_info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get user answers\n",
    "cursor = db.useranswers.find()\n",
    "users= [item for item in cursor]\n",
    "data = list(db.useranswers.find())\n",
    "data = pd.DataFrame(data)\n",
    "data.head(10)\n",
    "# create a pivot table where each user has one row and placeholders as columns\n",
    "pivot_table = data.pivot_table(index = 'user', columns = 'placeholder', values = 'originalAnswer', aggfunc = 'first')\n",
    "#reset index so the user will be presented as column and not index\n",
    "df = pivot_table.reset_index(level = 'user', inplace = False)\n",
    "website_info = WebsiteInfo()\n",
    "df['SiteDescription'] = df['user'].apply(lambda x: website_info.get_user_website_info('production', x))\n",
    "df['SiteDescription'] = df['SiteDescription'].astype(str)\n",
    "user = 'zuzusandals@gmail.com'\n",
    "user_info = df.loc[df['user'] == user]\n",
    "user_info.to_dict()\n",
    "global_calendar = global_calendar\n",
    "keyword = 'Barefoot Sandals'\n",
    "n_best = 5\n",
    "start_date  = datetime.date(2023, 2, 12)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = predict_best_calendar_events(user_info, keyword, start_date, n_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function result\n",
    "events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
