{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92d81c1-670a-499b-9a54-83ffc3bacb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6567952-4d89-4bca-b805-6cf48f9ae110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import tensorflow_hub as hub\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "from marktrix.helpers import Helper\n",
    "from marktrix.calendar import Calendar, global_calendar\n",
    "from marktrix.user_data import UserData\n",
    "from marktrix.website_info import WebsiteInfo\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Load your API key from an environment variable or secret management service\n",
    "openai.api_key = \"sk-9GD2atPAt9M1Od4YaPWIew7J3BNSlWKiO1d0Z7z3\"\n",
    "\n",
    "#load universal sentence encoder\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "embed = hub.load(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a1b556-cb87-41f7-81ff-c1b0e19cbfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaeee052-ffdf-4a4b-b5e9-1fe5eec9ad08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ce6b15-ca49-4a81-a8fa-f13c7f5c1613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mongo_url = os.environ.get(\"MARKTRIX_MONGO\")\n",
    "client = MongoClient(mongo_url)\n",
    "db = client['marktrix-production']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ebdfe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:49: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:49: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "C:\\Users\\One1\\AppData\\Local\\Temp\\ipykernel_19504\\2458016291.py:49: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if  target_customer_and_trends_text is not '':\n"
     ]
    }
   ],
   "source": [
    "#a function that return max events embed similarity to user and target audience \n",
    "def predict_best_calendar_events(user_info, global_calendar, start_date, end_date, n_best):\n",
    "    #user and website info\n",
    "    company_name = Helper.get_object_field(user_info, 'CompanyName')\n",
    "    company_industry = Helper.get_object_field(user_info, 'OwnIndustry')\n",
    "    site_desc = Helper.get_object_field(user_info, 'SiteDescription')\n",
    "    sol_desc = Helper.get_object_field(user_info, 'SolutionDescription')\n",
    "    num_one_benefit = Helper.get_object_field(user_info, 'NumberOneBenefit')\n",
    "    company_size = Helper.get_object_field(user_info, 'OwnCompanySize') \n",
    "    #product_categories = Helper.list_to_text(Helper.get_object_field(user_info, 'MainProductCategories'))\n",
    "    #business_model = Helper.get_object_field(user_info, 'BusinessModel')  # for Tone\n",
    "    #business_model = Helper.business_model_desc(business_model)\n",
    "    #how_customer_deal_with_needs = Helper.get_object_field(user_info, 'HowCustomerDealWithNeeds')\n",
    "    #sol_change = Helper.get_object_field(user_info, 'WhatYourSolutionChange')\n",
    "    #why_sol_important = Helper.get_object_field(user_info, 'WhySolutionImportant')\n",
    "    company_text = company_name + ' ' + company_industry + ' ' + site_desc + ' ' + sol_desc + ' ' + num_one_benefit +  ' ' + company_size \n",
    "                 # + '\\nBusiness Model\\n' + business_model \\\n",
    "                  # + '\\nProduct Categories\\n' + product_categories  \\\n",
    "   \n",
    "    \n",
    "    # target customer info\n",
    "    target_customer_description = Helper.get_object_field(user_info, 'TargetCustomerDescription')\n",
    "    positive_trends = Helper.get_object_field(user_info, 'PositiveTrends')\n",
    "    \n",
    "    target_customer_ages = Helper.get_object_field(user_info, 'TargetCustomerAges')\n",
    "    if target_customer_ages != '' and type(target_customer_ages) == list:\n",
    "        target_customer_ages = [Helper.customer_age_to_text(age) for age in target_customer_ages]\n",
    "        target_customer_ages = Helper.list_to_text(target_customer_ages)\n",
    "\n",
    "    target_customer_gender = Helper.get_object_field(user_info, 'TargetCustomerGender')\n",
    "    if target_customer_gender != '' and type(target_customer_gender) == list:\n",
    "        target_customer_gender = Helper.list_to_text(target_customer_gender)\n",
    "\n",
    "    target_customer_geo = Helper.get_object_field(user_info, 'TargetCustomerGeography')\n",
    "    if target_customer_geo != '' and type(target_customer_geo) == list:\n",
    "        target_customer_geo = Helper.list_to_text(target_customer_geo)\n",
    "\n",
    "     # decide if to use old or new\n",
    "    if target_customer_ages or target_customer_gender or target_customer_geo:\n",
    "        target_customer_description = target_customer_ages + ' '  + target_customer_gender+ ' ' + target_customer_geo\n",
    "    \n",
    "    \n",
    "    target_customer_and_trends_text = target_customer_description + ' ' + positive_trends\n",
    "   \n",
    "    #create embeddings from company's text and target customers\n",
    "    company_embed = embed(company_text)\n",
    "    \n",
    "    #If target customer text and trends is empty use Company_text\n",
    "    if  target_customer_and_trends_text is not '':\n",
    "        target_customers_embed = embed(target_customer_and_trends_text)\n",
    "    else: \n",
    "        target_customers_embed = embed(company_text)\n",
    "\n",
    "    \n",
    "    # will hold info for each date\n",
    "    calendar_d = global_calendar.cdays\n",
    "    calendar_m = global_calendar.mdays\n",
    "    calendar_m = pd.DataFrame(calendar_m)\n",
    "    calendar_d = pd.DataFrame(calendar_d)\n",
    "    all_events = pd.concat([calendar_m, calendar_d])\n",
    "    all_events = all_events[['name','desc', 'date']]\n",
    "    all_events['date'] = pd.to_datetime(all_events['date'])\n",
    "    all_events['date'] = all_events['date'].dt.date\n",
    "    all_events = all_events.drop_duplicates(subset=['name'])\n",
    "    mask = (all_events['date'] > start_date) & (all_events['date'] <= end_date)\n",
    "    concurrent_events = all_events.loc[mask]\n",
    "    concurrent_events_name = concurrent_events['name'] \n",
    "    concurrent_events_desc = concurrent_events['desc'] \n",
    "    concurrent_events['text'] = concurrent_events_name + ' ' + concurrent_events_desc\n",
    "    #create embeddings from concurrent events texts \n",
    "    concurrent_events_embed = embed(concurrent_events['text'])\n",
    "   \n",
    "    #calculate target customer embed correlation with concurrent_events_embed \n",
    "    target_event_cos_sim =  tf.keras.losses.cosine_similarity(concurrent_events_embed, target_customers_embed)\n",
    "    #target_cosine_sim = pd.DataFrame(data = target_event_cor)\n",
    "    \n",
    "\n",
    "    #calculate company embed correlation with concurrent_events_embed\n",
    "    company_event_cos_sim =  tf.keras.losses.cosine_similarity(concurrent_events_embed, company_embed)\n",
    "    #company_cosine_sim = pd.DataFrame(data = company_event_cor)\n",
    "\n",
    "    #calculates a similarity score based on combination of company and target customers similarity scores\n",
    "    similarity_score = target_event_cos_sim*0.8 + company_event_cos_sim*0.2\n",
    "    concurrent_events['similarity_score'] =  similarity_score\n",
    "    df = concurrent_events.nlargest(n_best, 'similarity_score')\n",
    "    df = df.sort_values(by=['similarity_score'], ascending=False)\n",
    "    \n",
    "    df= df[['name','desc', 'date','similarity_score']]\n",
    "    \n",
    "    return df \n",
    "    #with dates (can be index), pred, event. - sorted top pred first, event is event object as in calendar (day or month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794450bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f55467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606d2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
